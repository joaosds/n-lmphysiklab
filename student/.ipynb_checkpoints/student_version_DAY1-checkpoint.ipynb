{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b992f15-c624-4819-bfd0-246efdd9657e",
   "metadata": {},
   "source": [
    "# DAY1 : Supervised Learning #\n",
    " ## (a) Feed-forward Neural Network ##\n",
    " For documentation reference: https://docs.pytorch.org/tutorials/beginner/basics/intro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a14260-1d77-49d6-bb13-3cb1c6c7f7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### LOAD THE REQUIRED MODULES ## \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d8a128-b8de-4287-8d22-580aebf10cb0",
   "metadata": {},
   "source": [
    "### Load dataset FASHIONMNIST from datasets ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf31036f-ea2c-4c9e-b25e-05fe361cba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "# TODO: Load training dataset (train=True)\n",
    "\n",
    "# TODO: Load test dataset (train=False)\n",
    "\n",
    "# Split train → train + validation\n",
    "\n",
    "train_size = 50_000\n",
    "val_size = len(train_val_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_val_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c39dc91-9786-40c7-aa94-063ef1fd4f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_names = [\n",
    "    \"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\n",
    "    \"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"\n",
    "]\n",
    "\n",
    "# TODO: Get a batch of images and labels from train_loader [Hint: Look up next(iter())]\n",
    "\n",
    "# TODO: Plot the first 12 images using matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3822a671-2718-41c5-a84b-9da91526a5a3",
   "metadata": {},
   "source": [
    "### Build fully connected feed-forward Neural Network ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf47bcbf-b54a-45df-b822-e70fba76b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Fully-connected neural network for Fashion-MNIST.\n",
    "    width — neurons per hidden layer\n",
    "    depth — number of hidden layers\n",
    "    dropout — dropout probability\n",
    "    \"\"\"\n",
    "    def __init__(self, width=256, depth=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "        in_features = 28 * 28\n",
    "\n",
    "        # TODO: Add 'depth' hidden layers\n",
    "        # Each hidden layer should include:\n",
    "        # Linear → ReLU → Dropout\n",
    "\n",
    "        # TODO: Add final Linear layer with output size = 10\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # Flatten input images\n",
    "        # TODO: Pass through the network\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9726d91e-8e7d-428b-8d46-39bb2b8db8d2",
   "metadata": {},
   "source": [
    "### Define the Loss function and optimizer ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1db51cb-4c3d-4026-899d-fe796fe0539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize the MLP and move it to device\n",
    "\n",
    "# TODO: Define CrossEntropyLoss\n",
    "\n",
    "# TODO: Define Adam optimizer with learning rate = 1e-3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628a9177-2fa2-4d70-af4a-27ccf78413c8",
   "metadata": {},
   "source": [
    "### Training process ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1040247-316b-4456-8349-98013fd4967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for xb, yb in tqdm(loader, desc=\"Training\", leave=False):\n",
    "         xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # TODO: Forward pass\n",
    "\n",
    "        # TODO: Compute loss\n",
    "\n",
    "        # TODO: Backpropagation\n",
    "\n",
    "        # TODO: Optimizer step\n",
    "\n",
    "        total_loss += loss.item()*xb.size(0)\n",
    "        correct += (out.argmax(1) == yb).sum().item()\n",
    "        total += xb.size(0)\n",
    "\n",
    "        pass\n",
    "\n",
    "    return total_loss / total, correct / total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e975168-443c-4371-b55f-bde2477ef67e",
   "metadata": {},
   "source": [
    "### Evaluation process ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36c1ab0-f020-42b4-bf80-7941faf46ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def eval_epoch(model, loader, name=\"Evaluating\"):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for xb, yb in tqdm(loader, desc=name, leave=False):\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        out = model(xb)\n",
    "        loss = criterion(out, yb)\n",
    "\n",
    "        total_loss += loss.item()*xb.size(0)\n",
    "        correct += (out.argmax(1) == yb).sum().item()\n",
    "        total += xb.size(0)\n",
    "\n",
    "    return total_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a15de4-2936-4844-b5e3-3789f92d0cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # TODO: Call train_epoch\n",
    "    # TODO: Call eval_epoch\n",
    "    # TODO: Save metrics\n",
    "    # TODO: Print results\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7524dd09-5ab4-41ba-a31c-475228819ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract loss and accuracy values from history\n",
    "\n",
    "# TODO: Plot using matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb650dc-aedc-4918-ad45-451084838bc8",
   "metadata": {},
   "source": [
    "### Evaluate the trained model on the test dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800b7fab-acd2-4c1b-946f-9ff98136f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Call eval_epoch on test_loader\n",
    "\n",
    "# TODO: Print test accuracy\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def show_predictions(model, loader, n=24):\n",
    "    model.eval()\n",
    "\n",
    "    # TODO: Get one batch from loader\n",
    "\n",
    "    # TODO: Run model and get predictions\n",
    "\n",
    "    # TODO: Plot images with predicted and true labels\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c7d0d2-88c0-4dcb-9a22-02273c8a7b42",
   "metadata": {},
   "source": [
    "## (b) Convolutional Neural Network ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c341cbe9-450f-4ce4-8862-535e91de7cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade9080e-cce7-42e8-88eb-bbfeccaa988b",
   "metadata": {},
   "source": [
    "CNNs expects image of shape (batch_size, channels, height, width)\n",
    "FASHIONMNIST: 1 channel, pixels 28*28\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec07793-86d2-4ba0-8f6e-40fd1905f385",
   "metadata": {},
   "source": [
    "### Convert image into tensors and normalise ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757bd1c5-c97e-48e0-95f0-f73639bd2667",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5256ada9-844a-4323-8c35-111e70ee6e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data ##\n",
    "\n",
    "train_ds = datasets.FashionMNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "val_ds   = datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=256, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d7222-e29d-4fd2-8aa6-ff26cf9f1d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # ----- Convolutional Layers -----\n",
    "        self.conv = nn.Sequential(\n",
    "            # TODO: Conv2d layer (1 → 32 channels, kernel size 3, padding 1)\n",
    "            # TODO: ReLU\n",
    "            # TODO: MaxPool2d with kernel size 2\n",
    "\n",
    "            # TODO: Conv2d layer (32 → 64 channels, kernel size 3, padding 1)\n",
    "            # TODO: ReLU\n",
    "            # TODO: MaxPool2d with kernel size 2\n",
    "        )\n",
    "\n",
    "        # ----- Fully Connected Layers -----\n",
    "        self.fc = nn.Sequential(\n",
    "            # TODO: Linear layer (64 * 7 * 7 → 128)\n",
    "            # TODO: ReLU\n",
    "            # TODO: Dropout (p = 0.4)\n",
    "            # TODO: Linear layer (128 → 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Pass input through conv layers\n",
    "        # TODO: Flatten feature maps\n",
    "        # TODO: Pass through fully connected layers\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e2a5363-a5bc-4ee8-aff7-8c1ff434f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize CNN and move it to device\n",
    "\n",
    "# TODO: Define CrossEntropyLoss\n",
    "\n",
    "# TODO: Define Adam optimizer (learning rate = 1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706e3236-2263-44f0-a221-1b5de024f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        # TODO: Move data to device\n",
    "\n",
    "        # TODO: Zero gradients\n",
    "\n",
    "        # TODO: Forward pass\n",
    "\n",
    "        # TODO: Compute loss\n",
    "\n",
    "        # TODO: Backward pass\n",
    "\n",
    "        # TODO: Optimizer step\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _,pred = torch.max(out,1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    train_losses.append(running_loss/len(train_loader))\n",
    "    train_accs.append(correct/total)\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Training Done\")\n",
    "    \n",
    "    # ---- VALIDATE ----\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x,y in val_loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            loss = criterion(out,y)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _,pred = torch.max(out,1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    val_losses.append(running_loss/len(val_loader))\n",
    "    val_accs.append(correct/total)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} \"\n",
    "          f\"Train Loss {train_losses[-1]:.3f}  Val Loss {val_losses[-1]:.3f}  \"\n",
    "          f\"Train Acc {train_accs[-1]*100:.2f}%  Val Acc {val_accs[-1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023de014-71d7-4a9d-b141-660d5896fc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot loss curves\n",
    "\n",
    "# TODO: Plot accuracy curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c296306b-b439-4e33-94a3-72cc3f663b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    \"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\n",
    "    \"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# TODO: Get one batch from val_loader\n",
    "# TODO: Run model forward pass\n",
    "# TODO: Get predicted labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23e4051-138d-4830-9b3b-492b8c043b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot first 8 images\n",
    "# Show:\n",
    "# Predicted label\n",
    "# True label\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LM_Lab",
   "language": "python",
   "name": "lmphysiklab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
